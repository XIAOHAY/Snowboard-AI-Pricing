# -*- coding: utf-8 -*-
"""
æ–‡ä»¶åï¼šllm/qwen_vl.py
åŠŸèƒ½ï¼šè°ƒç”¨é˜¿é‡Œäº‘åƒé—® VL æ¨¡å‹åˆ†æå›¾ç‰‡ï¼ˆå«é‡è¯•æœºåˆ¶ä¸å‹å·è¯†åˆ«ï¼‰
çŠ¶æ€ï¼šæ”¹è¿›ç‰ˆ (æ”¯æŒç”¨æˆ·çº¿ç´¢æ³¨å…¥)
"""
import os
import json
import time
import dashscope
from dashscope import MultiModalConversation
from dotenv import load_dotenv

# ===============================
# 1. åˆå§‹åŒ–é…ç½®
# ===============================
# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è·å–å¹¶è®¾ç½® API Key
api_key = os.getenv("DASHSCOPE_API_KEY")
if not api_key:
    # å°è¯•è¯»å– SNOWBOARD_API_KEYS (å…¼å®¹å¤„ç†)
    api_key = os.getenv("SNOWBOARD_API_KEYS")

if not api_key:
    # è¿™é‡Œä¸ºäº†é˜²å´©ï¼Œå¦‚æœæ²¡è¯»åˆ°ç¯å¢ƒå˜é‡ï¼Œå¯ä»¥æ‰“å°è­¦å‘Šè€Œä¸æ˜¯ç›´æ¥æŠ›å¼‚å¸¸ï¼Œæˆ–è€…ä¿æŒåŸæ ·
    # raise ValueError("é”™è¯¯ï¼šæœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEYã€‚è¯·æ£€æŸ¥ .env æ–‡ä»¶ã€‚")
    print("âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ° DASHSCOPE_API_KEYï¼Œåç»­è°ƒç”¨å¯èƒ½ä¼šå¤±è´¥ã€‚")

dashscope.api_key = api_key
print("ã€DEBUGã€‘DashScope SDK åˆå§‹åŒ–æˆåŠŸ")


# ===============================
# 2. è¾…åŠ©å·¥å…·å‡½æ•°
# ===============================
def clean_json_text(text: str) -> str:
    """æ¸…ç†å¤§æ¨¡å‹è¿”å›çš„ markdown æ ¼å¼ï¼Œæå–çº¯ JSON å­—ç¬¦ä¸²"""
    if not text:
        return ""
    text = text.strip()
    # å»æ‰ markdown çš„ä»£ç å—æ ‡è®°
    if text.startswith("```"):
        text = text.replace("```json", "")
        text = text.replace("```", "")
    return text.strip()


# ===============================
# 3. å®šä¹‰ Prompt (æç¤ºè¯)
# ===============================
# ä¿®æ”¹ llm/qwen_vl.py ä¸­çš„ DEFAULT_PROMPT

DEFAULT_PROMPT = """
ä½ æ˜¯ä¸€åæå…¶ä¸¥è‹›çš„äºŒæ‰‹æ»‘é›ªæ¿é‰´å®šä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®å›¾ç‰‡å®¢è§‚æè¿°æŸä¼¤ï¼Œå¹¶ä¾æ®ä¸¥æ ¼æ ‡å‡†è¿›è¡Œè¯„åˆ†ã€‚
ã€é‡è¦æç¤ºã€‘
1. å›¾ç‰‡ä¸­å¯èƒ½åŒ…å«ç«–æ’ã€æ—‹è½¬æˆ–è‰ºæœ¯å­—ä½“çš„ LOGOï¼Œè¯·ä»”ç»†è¾¨è®¤ã€‚
2. **æ³¨æ„åŒºåˆ†é€šç”¨è¯ä¸å“ç‰Œ**ï¼šä¾‹å¦‚ "GRAY", "RIDE", "SIGNAL", "YES", "FLOW" åœ¨è¿™é‡Œæ˜¯ã€å“ç‰Œåã€‘ï¼Œè€Œä¸æ˜¯æ™®é€šå•è¯ã€‚
3. è¯·å¿½ç•¥æ°´å°æ–‡å­—ï¼ˆå¦‚â€œé—²é±¼â€ã€â€œå°çº¢ä¹¦â€ç­‰ï¼‰ã€‚

ã€å·²çŸ¥å“ç‰Œåˆ—è¡¨å‚è€ƒã€‘
BURTON, SALOMON, CAPITA, NITRO, K2, RIDE, ROME SDS, JONES, LIB TECH, GNU, 
GRAY, OGASAKA, BC STREAM, MOSS, GENTEMSTICK, YONEX, 011 ARTISTIC, RICE28,
BATALEON, LOBSTER, ARBOR, DC, HEAD, FLOW, FLUX, UNION, NIDECKER, YES,
NOBADAY, VECTOR, REV, TERROR.
ã€ç¬¬ä¸€æ­¥ï¼šå¼ºåˆ¶è§†è§‰æ¨ç†ã€‘
åœ¨è¾“å‡º JSON ä¹‹å‰ï¼Œä½ å¿…é¡»å…ˆåœ¨å¿ƒä¸­ï¼ˆæˆ–ä½œä¸º"thinking"å­—æ®µï¼‰ç¡®è®¤ä»¥ä¸‹ç»†èŠ‚ï¼š
1. **æ¿é¢ (Top sheet)**ï¼šæ˜¯å¦æœ‰è¾¹ç¼˜å´©è£‚(Chipping)ï¼Ÿå›ºå®šå™¨å®‰è£…åŒºæ˜¯å¦æœ‰å‹ç—•ï¼Ÿ
2. **æ¿åº• (Base)**ï¼šæ˜¯å¦æœ‰éœ²èŠ¯æ·±åˆ’ç—•(Core Shot)ï¼Ÿè¿˜æ˜¯ä»…ä»…æ˜¯å‘ä¸ç—•(Hairline)ï¼Ÿ
3. **æ¿åˆƒ (Edge)**ï¼šæ˜¯å¦æœ‰æ–­è£‚ï¼Ÿæ˜¯å¦æœ‰é”ˆè¿¹ï¼ˆæµ®é”ˆè¿˜æ˜¯è…èš€ï¼‰ï¼Ÿ

ã€ç¬¬äºŒæ­¥ï¼šä¸¥æ ¼è¯„åˆ†æ ‡å‡† (Rubric)ã€‘
è¯·å®Œå…¨æŒ‰ç…§ä»¥ä¸‹æ ‡å‡†æ‰“åˆ†ï¼Œç¦æ­¢è‡ªç”±å‘æŒ¥ï¼š
- **9-10åˆ†**ï¼šå……æ–°ã€‚ä»…æœ‰æå…¶è½»å¾®çš„ä½¿ç”¨ç—•è¿¹ï¼Œæ— è‚‰çœ¼å¯è§åˆ’ç—•ã€‚
- **7-8åˆ†**ï¼šè‰¯å¥½ã€‚æ¿é¢æœ‰å°‘é‡è½»å¾®åˆ’ç—•ï¼Œæ¿åˆƒæ— é”ˆæˆ–ä»…æœ‰æµ®é”ˆï¼Œæ¿åº•æ— æ·±ä¼¤ã€‚
- **5-6åˆ†**ï¼šä¼Šæ‹‰å…‹æˆè‰²ã€‚æ¿é¢è¾¹ç¼˜æœ‰å´©è£‚ï¼Œæ¿åº•æœ‰æ˜æ˜¾åˆ’ç—•ä½†æœªæ¼èŠ¯ï¼Œæ¿åˆƒæœ‰é”ˆã€‚
- **1-4åˆ†**ï¼šæŠ¥åºŸã€‚æ¿åˆƒæ–­è£‚ã€æ¿åº•æ¼èŠ¯ã€æ¿å±‚å¼€è£‚ã€‚

ã€ç¬¬ä¸‰æ­¥ï¼šè¾“å‡ºæ ¼å¼ã€‘
è¯·è¾“å‡ºä¸”ä»…è¾“å‡ºä»¥ä¸‹ JSON æ ¼å¼ï¼š
{
  "reasoning": "ä¸€å¥è¯æè¿°ä½ çœ‹åˆ°çš„æŸä¼¤è¯æ®ï¼ˆä¾‹å¦‚ï¼šæ¿å¤´å·¦ä¾§æœ‰æ˜æ˜¾çš„è¾¹ç¼˜å´©è£‚ï¼Œæ¿åº•æœ‰ä¸¤æ¡æµ…åˆ’ç—•ï¼‰",
  "brand": "å“ç‰Œè‹±æ–‡å¤§å†™ (ä¾‹å¦‚ BURTON)",
  "possible_model": "å‹å·çŒœæµ‹",
  "condition_score": "1-10çš„æ•´æ•°",
  "base_damage": "æ¿åº•å…·ä½“æŸä¼¤ (æ— /è½»å¾®/ä¸¥é‡)",
  "edge_damage": "æ¿åˆƒå…·ä½“æŸä¼¤ (æ— /æµ®é”ˆ/è…èš€/æ–­è£‚)",
  "can_use": true
  "is_old_model": true æˆ– false (åˆ¤æ–­ä¾æ®ï¼šæ¿é¢è®¾è®¡é£æ ¼æ˜¯å¦é™ˆæ—§ï¼Œæˆ–è€…æ˜æ˜¾çš„æ—§æ¬¾LOGOã€‚å¦‚æœæ— æ³•åˆ¤æ–­ï¼Œè¿”å› false),
}
"""



# ===============================
# 4. æ ¸å¿ƒå‡½æ•°ï¼šåˆ†æå›¾ç‰‡
# ===============================
def analyze_snowboard_image(image_path: str, user_hint: str = None) -> dict:
    """
    è°ƒç”¨åƒé—® VL æ¨¡å‹åˆ†æé›ªæ¿å›¾ç‰‡
    :param image_path: å›¾ç‰‡è·¯å¾„
    :param user_hint: ç”¨æˆ·æä¾›çš„çº¿ç´¢ (å¯é€‰)
    """

    # ğŸ”¥ åŠ¨æ€æ„å»º Promptï¼šå¦‚æœç”¨æˆ·ç»™äº†çº¿ç´¢ï¼Œæ‹¼æ¥åˆ° Prompt é‡Œ
    final_prompt = DEFAULT_PROMPT
    if user_hint and user_hint.strip():
        final_prompt += f"""
        \nã€ç”¨æˆ·é¢å¤–æç¤ºã€‘
        ç”¨æˆ·æŒ‡å‡ºè¿™å¼ å›¾ç‰‡ä¸­çš„é›ªæ¿å¯èƒ½æ˜¯ï¼š"{user_hint}"ã€‚
        è¯·ä»¥æ­¤ä¸ºé‡è¦çº¿ç´¢ï¼Œä¼˜å…ˆåœ¨ç”»é¢ä¸­éªŒè¯è¯¥å“ç‰Œæˆ–å‹å·ç‰¹å¾ã€‚
        å¦‚æœç”»é¢æ˜æ˜¾ä¸ç”¨æˆ·æç¤ºä¸ç¬¦ï¼Œè¯·å¿½ç•¥æç¤ºï¼Œä»¥ç”»é¢ä¸ºå‡†ã€‚
        """

    max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
    retry_delay = 2  # æ¯æ¬¡å¤±è´¥ç­‰å¾…ç§’æ•°

    last_error = None
    response = None

    # --- å¼€å§‹é‡è¯•å¾ªç¯ ---
    for attempt in range(max_retries):
        try:
            print(f"ğŸš€ æ­£åœ¨è°ƒç”¨é˜¿é‡Œäº‘è§†è§‰æ¨¡å‹ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)...")

            # å…¼å®¹ Windows è·¯å¾„
            local_file_path = f"file://{image_path}" if not image_path.startswith("file://") else image_path

            response = MultiModalConversation.call(
                model="qwen-vl-max",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"image": local_file_path},
                            {"text": final_prompt}  # ä½¿ç”¨åŒ…å«çº¿ç´¢çš„ Prompt
                        ]
                    }
                ],
                # ğŸ”¥ã€æ ¸å¿ƒä¿®æ”¹ã€‘åŠ ä¸Šè¿™ä¸¤è¡Œå‚æ•°ï¼Œç»™è§†è§‰æ¨¡å‹â€œé™æ¸©â€
                temperature = 0.01,  # æ¥è¿‘ 0 è¡¨ç¤ºæåº¦ç†æ€§ï¼Œæ¯æ¬¡è¾“å‡ºå‡ ä¹ä¸€è‡´
                top_p = 0.1,  # é™åˆ¶å®ƒçš„å‘æ•£æ€ç»´ï¼Œåªé€‰æ¦‚ç‡æœ€é«˜çš„è¯
            )

            # æ£€æŸ¥ HTTP çŠ¶æ€ç 
            if response.status_code == 200:
                print("âœ… æ¨¡å‹è°ƒç”¨æˆåŠŸï¼")
                break  # æˆåŠŸäº†å°±è·³å‡ºå¾ªç¯
            else:
                error_msg = f"APIé”™è¯¯ç : {response.code} - {response.message}"
                print(f"âš ï¸ {error_msg}")
                raise RuntimeError(error_msg)

        except Exception as e:
            print(f"âŒ ç¬¬ {attempt + 1} æ¬¡è¯·æ±‚å¼‚å¸¸: {str(e)}")
            last_error = e
            if attempt < max_retries - 1:
                print(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                time.sleep(retry_delay)
            else:
                print("ğŸ’€ é‡è¯•æ¬¡æ•°è€—å°½ã€‚")

    # --- å¾ªç¯ç»“æŸåçš„å¤„ç† ---

    # å¦‚æœæœ€åä¸€æ¬¡ response ä¾ç„¶æ˜¯ç©ºçš„æˆ–è€…å¤±è´¥
    if response is None or response.status_code != 200:
        # ä¸ºäº†ä¸è®©ç¨‹åºå´©æ‰ï¼Œè¿”å›ä¸€ä¸ªå…œåº•çš„é”™è¯¯ JSON
        print(f"ã€ä¸¥é‡é”™è¯¯ã€‘æ— æ³•è·å–æ¨¡å‹ç»“æœ: {last_error}")
        return {
            "brand": "UNKNOWN",
            "possible_model": "UNKNOWN",
            "condition_score": 5,
            "can_use": True,
            "base_damage": "ç½‘ç»œé”™è¯¯ï¼Œæ— æ³•åˆ†æ",
            "error": "NETWORK_ERROR"
        }

    # æ£€æŸ¥ output å­—æ®µ
    if "output" not in response or not response.output.choices:
        return {
            "brand": "UNKNOWN",
            "error": "EMPTY_RESPONSE"
        }

    # æå–æ–‡æœ¬å†…å®¹
    content_list = response.output.choices[0].message.content
    raw_text = ""

    for item in content_list:
        if "text" in item:
            raw_text += item["text"]

    # æ¸…æ´—å¹¶è§£æ JSON
    clean_text = clean_json_text(raw_text)

    try:
        data = json.loads(clean_text)
        return data
    except Exception as e:
        print(f"ã€JSONè§£æå¤±è´¥ã€‘åŸå§‹æ–‡æœ¬: {raw_text}")
        # è¿”å›å…œåº•æ•°æ®
        return {
            "brand": "UNKNOWN",
            "possible_model": "UNKNOWN",
            "condition_score": 5,
            "can_use": True,
            "error": "JSON_PARSE_ERROR"
        }